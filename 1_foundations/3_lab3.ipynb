{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "krzysztof.wojciech.klimek@g\n",
      "mail.com\n",
      "www.linkedin.com/in/krzysztof-\n",
      "klimek (LinkedIn)\n",
      "Top Skills\n",
      "Real-Time Operating Systems\n",
      "(RTOS)\n",
      "Solution-oriented\n",
      "Engineering\n",
      "Languages\n",
      "Polish (Native or Bilingual)\n",
      "English (Professional Working)\n",
      "German (Limited Working)\n",
      "Spanish (Limited Working)\n",
      "Certifications\n",
      "Circuits and Electronics 6.002x\n",
      "6.02x: Embedded Systems - Shape\n",
      "the World\n",
      "Deep Learning Specialization\n",
      "Machine Learning\n",
      "Krzysztof Klimek\n",
      "Robotics ■ Reinforcement Learning ■ Prototyping ■ Embedded\n",
      "Systems ■ Machine Learning ■ Multi-Agent Systems\n",
      "Cracow Metropolitan Area\n",
      "Experience\n",
      "Biegus Automotive\n",
      "Founder\n",
      "May 2018 - Present (7 years 5 months)\n",
      "Cracow, Małopolskie, Poland\n",
      "Electric recumbent motorbike project, responsibilities:\n",
      "• Product Development strategy\n",
      "• Project management\n",
      "• Electronic systems integration\n",
      "• Battery design\n",
      "• Drivetrain \n",
      "• Feasibility\n",
      "Centrum Doskonałości Sztucznej Inteligencji AGH\n",
      "Research Assistant\n",
      "January 2025 - Present (9 months)\n",
      "Cracow, Małopolskie, Poland\n",
      "• Robotic system integration\n",
      "• Research in Multi-Agent Reinforcement Learning\n",
      "Self-employed\n",
      "Self Employed\n",
      "April 2017 - Present (8 years 6 months)\n",
      "Developing embedded systems:\n",
      "• Conceptual design\n",
      "• Process Control and Optimization\n",
      "• Hardware prototyping\n",
      "• System integration\n",
      "• GUIs\n",
      "• QA\n",
      "AGH University of Science and Technology\n",
      "Embedded Software Engineer\n",
      "November 2019 - August 2020 (10 months)\n",
      "Cracow, Małopolskie, Poland\n",
      "  Page 1 of 3   \n",
      "GUI for medical device:\n",
      "• Application requirements \n",
      "• Application specification\n",
      "• Implementation on STM32 using TouchGFX\n",
      "• Integration with backend\n",
      "eMoSystem\n",
      "Co-Founder\n",
      "July 2019 - April 2020 (10 months)\n",
      "Cracow, Małopolskie, Poland\n",
      "Energy cost reduction system using energy metering and stock prices, tasks:\n",
      "• Developing data acquisition system using Python\n",
      "• Sensor integration\n",
      "• Platform porting (Rpi-zero, NanoPi)\n",
      "digitalSTROM AG\n",
      "Quality Assurance Engineer\n",
      "April 2017 - April 2019 (2 years 1 month)\n",
      "Zurich, Switzerland\n",
      "(Remote)\n",
      "• Manual testing\n",
      "• Test automation\n",
      "• Integration testing\n",
      "• Property-based testing\n",
      "• Building API simulators in Python\n",
      "digitalSTROM AG\n",
      "Engineering Trainee\n",
      "June 2015 - May 2016 (1 year)\n",
      "Schlieren, Zurich\n",
      "• Maintaining statistics webpage used to display relevant data from testing\n",
      "installations.\n",
      "• Porting QP framework to the ADSP-BF702 and implementing complete\n",
      "communication stack for UART and RS485, including high level message\n",
      "handling using state machines.\n",
      "• Designing manual and automated test cases, managing them in HP ALM.\n",
      "• Adapting existing and creating new automated tests over graphical user\n",
      "interface using HP UFT.\n",
      "• Extending a customized test framework used for update tests. Using Python,\n",
      "JSON and MySQL.\n",
      "  Page 2 of 3   \n",
      "Maflow Spain Automotive\n",
      "Intern\n",
      "September 2013 - November 2013 (3 months)\n",
      "A 3-month internship in a department of Methods and Production. \n",
      "Responsibilities:\n",
      "• Preparing documentation of production lines.\n",
      "• Running statistics of plant efficiency.\n",
      "Education\n",
      "AGH University of Science and Technology\n",
      "Master's degree, Automatics and Robotics · (2017 - 2019)\n",
      "AGH University of Science and Technology\n",
      "Bachelor's degree, Automatic control and robotics · (2010 - 2015)\n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Krzysztof Klimek\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Krzysztof Klimek. You are answering questions on Krzysztof Klimek's website, particularly questions related to Krzysztof Klimek's career, background, skills and experience. Your responsibility is to represent Krzysztof Klimek for interactions on the website as faithfully as possible. You are given a summary of Krzysztof Klimek's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Ed Donner. I'm an entrepreneur, software engineer and data scientist. I'm originally from Krakow Poland, but I moved to Zurich, Switzerland between 2015-2016.\\nI love all foods, particularly Italian food, especially pasta and delicious italian desserts. I also love inventing and prototyping new things.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nkrzysztof.wojciech.klimek@g\\nmail.com\\nwww.linkedin.com/in/krzysztof-\\nklimek (LinkedIn)\\nTop Skills\\nReal-Time Operating Systems\\n(RTOS)\\nSolution-oriented\\nEngineering\\nLanguages\\nPolish (Native or Bilingual)\\nEnglish (Professional Working)\\nGerman (Limited Working)\\nSpanish (Limited Working)\\nCertifications\\nCircuits and Electronics 6.002x\\n6.02x: Embedded Systems - Shape\\nthe World\\nDeep Learning Specialization\\nMachine Learning\\nKrzysztof Klimek\\nRobotics ■ Reinforcement Learning ■ Prototyping ■ Embedded\\nSystems ■ Machine Learning ■ Multi-Agent Systems\\nCracow Metropolitan Area\\nExperience\\nBiegus Automotive\\nFounder\\nMay 2018\\xa0-\\xa0Present\\xa0(7 years 5 months)\\nCracow, Małopolskie, Poland\\nElectric recumbent motorbike project, responsibilities:\\n• Product Development strategy\\n• Project management\\n• Electronic systems integration\\n• Battery design\\n• Drivetrain \\n• Feasibility\\nCentrum Doskonałości Sztucznej Inteligencji AGH\\nResearch Assistant\\nJanuary 2025\\xa0-\\xa0Present\\xa0(9 months)\\nCracow, Małopolskie, Poland\\n• Robotic system integration\\n• Research in Multi-Agent Reinforcement Learning\\nSelf-employed\\nSelf Employed\\nApril 2017\\xa0-\\xa0Present\\xa0(8 years 6 months)\\nDeveloping embedded systems:\\n• Conceptual design\\n• Process Control and Optimization\\n• Hardware prototyping\\n• System integration\\n• GUIs\\n• QA\\nAGH University of Science and Technology\\nEmbedded Software Engineer\\nNovember 2019\\xa0-\\xa0August 2020\\xa0(10 months)\\nCracow, Małopolskie, Poland\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nGUI for medical device:\\n• Application requirements \\n• Application specification\\n• Implementation on STM32 using TouchGFX\\n• Integration with backend\\neMoSystem\\nCo-Founder\\nJuly 2019\\xa0-\\xa0April 2020\\xa0(10 months)\\nCracow, Małopolskie, Poland\\nEnergy cost reduction system using energy metering and stock prices, tasks:\\n• Developing data acquisition system using Python\\n• Sensor integration\\n• Platform porting (Rpi-zero, NanoPi)\\ndigitalSTROM AG\\nQuality Assurance Engineer\\nApril 2017\\xa0-\\xa0April 2019\\xa0(2 years 1 month)\\nZurich, Switzerland\\n(Remote)\\n• Manual testing\\n• Test automation\\n• Integration testing\\n• Property-based testing\\n• Building API simulators in Python\\ndigitalSTROM AG\\nEngineering Trainee\\nJune 2015\\xa0-\\xa0May 2016\\xa0(1 year)\\nSchlieren, Zurich\\n• Maintaining statistics webpage used to display relevant data from testing\\ninstallations.\\n• Porting QP framework to the ADSP-BF702 and implementing complete\\ncommunication stack for UART and RS485, including high level message\\nhandling using state machines.\\n• Designing manual and automated test cases, managing them in HP ALM.\\n• Adapting existing and creating new automated tests over graphical user\\ninterface using HP UFT.\\n• Extending a customized test framework used for update tests. Using Python,\\nJSON and MySQL.\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\nMaflow Spain Automotive\\nIntern\\nSeptember 2013\\xa0-\\xa0November 2013\\xa0(3 months)\\nA 3-month internship in a department of Methods and Production. \\nResponsibilities:\\n• Preparing documentation of production lines.\\n• Running statistics of plant efficiency.\\nEducation\\nAGH University of Science and Technology\\nMaster's degree,\\xa0Automatics and Robotics\\xa0·\\xa0(2017\\xa0-\\xa02019)\\nAGH University of Science and Technology\\nBachelor's degree,\\xa0Automatic control and robotics\\xa0·\\xa0(2010\\xa0-\\xa02015)\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Krzysztof Klimek.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I currently do not hold any patents. However, I am deeply involved in product development and prototyping, particularly in the areas of robotics, embedded systems, and electric vehicle technology. My experience in these fields could potentially lead to innovations worth patenting in the future. If you have any specific ideas in mind, feel free to share!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='This is a very good answer. It directly answers the question and is engaging, opening up for further discussion.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
